# Invention and Thesis Creation
## 1. Case Study
[
	Hill, Kashmir.
	"Wrongfully Accused by an Algorithm".
	*The New York Times*,
	June 24, 2020
](https://www.nytimes.com/2020/06/24/technology/facial-recognition-arrest.html)

Robert Julian-Borchak Williams, an African-American male, is falsely arrested
by the Detroit Police Department due to the use of a flawed facial recognition
system.

## 2. Application of 2 Class Readings
Peggy McIntosh's "White Privilege: Unpacking the Invisible Knapsack": The
ignorance of systemic racism by tech companies and machine learning engineers
is the same ignorance which allows white privilege to function.

Koritha Mitchell's "Identifying White Mediocrity and Know-Your-Place
Aggression": Mitchell describes the concept of manufactured innocence for the
demographic of straight white men, which is reinforced by the behavior of
machine learning algorithms.

## 3. Choosing a Concept
White privilege seems most relevant to this case study, because the ignorance
for systemic racism is a reason for why machine learning systems are biased
(and still implemented anyway).

## 4. Choosing a Reading
Peggy McIntosh's "White Privilege: Unpacking the Invisible Knapsack".

## 5. Instantiating the Question
To what extent is the concept of **white privilege** a productive or
meaningful way for us to understand and reflect on your case study? Why? (So
what?)

## 6. Rating on the Unproductive/Unmeaningful - Productive/Meaningful Spectrum
7.8/10. (Too much water.)

## 7. Answering "Why?"
The mechanism by which white privilege functions is the same that causes
artifical intelligence research and development to create systems that are
biased against people of color. Both are rooted in the ignorance for systemic
racism.

## 8. Answering "So What?"
In order to create helpful and egalitarian technology, white privilege must be
addressed.

## 9. Thesis Statement Draft
The concept of white privilege is a productive way to view Robert
Julian-Borchak Williams's incident with the Detroit Police Department, and
more generally, the problem of racial bias in machine learning systems because
both are rooted in the ignorance for systemic causes of racism. Before
implementing artificial intelligence technology, white privilege must be
addressed.
